{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "config = yaml.safe_load(open(\"../config/datasets.yml\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"AbbySlidingWindow\"\n",
    "DATASET_DIR = config[DATASET][\"path\"]\n",
    "print(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.utils import get_files_of_type\n",
    "print(get_files_of_type(\"/share/j_sun/jth264/abby/test/GX017042_clips_and_labels\", \".txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.data.dataset import get_dataset\n",
    "dataset = get_dataset(\n",
    "    DATASET,\n",
    "    DATASET_DIR, \n",
    "    model_name=\"videomae\", \n",
    "    train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(13032/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for frame, label in tqdm(dataset):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame, label = next(iter(dataset))\n",
    "print(frame.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.utils import get_files_of_type\n",
    "import numpy as np\n",
    "annotation_files = get_files_of_type(DATASET_DIR, \".txt\")\n",
    "\n",
    "annotations = []\n",
    "for file in annotation_files:\n",
    "    annotations.append(np.loadtxt(file, delimiter=\"\\t\"))\n",
    "\n",
    "annotations = np.concatenate(annotations, axis=0)\n",
    "annotations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.data.dataset import AbbyDataset\n",
    "from fish_benchmark.models import get_input_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transform = get_input_transform(\"videomae\")\n",
    "dataset = AbbyDataset(\n",
    "        DATASET_DIR, \n",
    "        train=True, \n",
    "        transform=input_transform, \n",
    "        label_type='onehot', \n",
    "        window_size=16, \n",
    "        tolerance_region = 7,\n",
    "        samples_per_window = 16,\n",
    "        step_size=1, \n",
    "        is_image_dataset=False\n",
    ")\n",
    "\n",
    "frame, label = next(iter(dataset))\n",
    "from fish_benchmark.debug import serialized_size\n",
    "print(serialized_size(frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "labels = []\n",
    "for frame, label in tqdm(dataset):\n",
    "    labels.append(label)\n",
    "\n",
    "labels = torch.stack(labels)\n",
    "print(labels.sum(axis=0)/labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch \n",
    "from fish_benchmark.debug import serialized_size\n",
    "x = torch.randn(16, 3, 224, 224)\n",
    "start = time.time()\n",
    "torch.save(x, \"/share/j_sun/jth264/test.pt\")\n",
    "print(\"Time:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = [torch.randn(16, 3, 224, 224) for _ in range(100)]\n",
    "stacked = torch.stack(clips)\n",
    "clip0 = stacked[0]\n",
    "\n",
    "print(clip0.storage().size())          # Very large! Entire tensor storage\n",
    "print(serialized_size(clip0))          # Very large! ~1GB, same as full tensor\n",
    "print(clip0.clone().storage().size())  # Just right! ~9MB worth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jth264/.conda/envs/benchmark/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fish_benchmark.data.preprocessors import TorchVisionPreprocessor\n",
    "from fish_benchmark.models import get_input_transform\n",
    "from fish_benchmark.data.dataset import get_dataset\n",
    "img_tensor = torch.randint(0, 256, (3, 480, 640), dtype=torch.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "DATASET = \"MikeFramesPatched\"\n",
    "MODEL =  None # \"multipatch_dino\"\n",
    "config = yaml.safe_load(open(\"../config/datasets.yml\", \"r\"))\n",
    "input_transform = get_input_transform(MODEL) if MODEL else None\n",
    "dataset = get_dataset(\n",
    "    DATASET, \n",
    "    path = config[DATASET]['path'], \n",
    "    augs=input_transform,\n",
    "    train=True, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[converting PIL image to numpy] took 0.016989 seconds\n",
      "[stacking patches] took 0.001108 seconds\n",
      "[converting to tensor] took 0.041207 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.042852 seconds\n",
      "[converting PIL image to numpy] took 0.009117 seconds\n",
      "[stacking patches] took 0.002237 seconds\n",
      "[converting to tensor] took 0.014322 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.016868 seconds\n",
      "[converting PIL image to numpy] took 0.008871 seconds\n",
      "[stacking patches] took 0.001096 seconds\n",
      "[converting to tensor] took 0.013202 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014633 seconds\n",
      "[converting PIL image to numpy] took 0.005022 seconds\n",
      "[stacking patches] took 0.001122 seconds\n",
      "[converting to tensor] took 0.011590 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013188 seconds\n",
      "[converting PIL image to numpy] took 0.003726 seconds\n",
      "[stacking patches] took 0.001146 seconds\n",
      "[converting to tensor] took 0.011006 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012444 seconds\n",
      "[converting PIL image to numpy] took 0.003258 seconds\n",
      "[stacking patches] took 0.001132 seconds\n",
      "[converting to tensor] took 0.011403 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012856 seconds\n",
      "[converting PIL image to numpy] took 0.004539 seconds\n",
      "[stacking patches] took 0.001230 seconds\n",
      "[converting to tensor] took 0.015319 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.016899 seconds\n",
      "[converting PIL image to numpy] took 0.008111 seconds\n",
      "[stacking patches] took 0.001040 seconds\n",
      "[converting to tensor] took 0.012692 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.014065 seconds\n",
      "[converting PIL image to numpy] took 0.004437 seconds\n",
      "[stacking patches] took 0.001490 seconds\n",
      "[converting to tensor] took 0.015415 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.017247 seconds\n",
      "[converting PIL image to numpy] took 0.004373 seconds\n",
      "[stacking patches] took 0.001084 seconds\n",
      "[converting to tensor] took 0.014109 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015517 seconds\n",
      "[converting PIL image to numpy] took 0.005355 seconds\n",
      "[stacking patches] took 0.001232 seconds\n",
      "[converting to tensor] took 0.012331 seconds\n",
      "[applying vision transform] took 0.000004 seconds\n",
      "[getting latest clip] took 0.013868 seconds\n",
      "[converting PIL image to numpy] took 0.003188 seconds\n",
      "[stacking patches] took 0.001771 seconds\n",
      "[converting to tensor] took 0.011372 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013498 seconds\n",
      "[converting PIL image to numpy] took 0.004137 seconds\n",
      "[stacking patches] took 0.001039 seconds\n",
      "[converting to tensor] took 0.011096 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012439 seconds\n",
      "[converting PIL image to numpy] took 0.003738 seconds\n",
      "[stacking patches] took 0.001112 seconds\n",
      "[converting to tensor] took 0.010982 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012372 seconds\n",
      "[converting PIL image to numpy] took 0.003384 seconds\n",
      "[stacking patches] took 0.001012 seconds\n",
      "[converting to tensor] took 0.013028 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014321 seconds\n",
      "[converting PIL image to numpy] took 0.004977 seconds\n",
      "[stacking patches] took 0.001306 seconds\n",
      "[converting to tensor] took 0.013923 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015515 seconds\n",
      "[converting PIL image to numpy] took 0.003780 seconds\n",
      "[stacking patches] took 0.001184 seconds\n",
      "[converting to tensor] took 0.012954 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014664 seconds\n",
      "[converting PIL image to numpy] took 0.013485 seconds\n",
      "[stacking patches] took 0.001448 seconds\n",
      "[converting to tensor] took 0.014091 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015937 seconds\n",
      "[converting PIL image to numpy] took 0.003534 seconds\n",
      "[stacking patches] took 0.001245 seconds\n",
      "[converting to tensor] took 0.013106 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014733 seconds\n",
      "[converting PIL image to numpy] took 0.004552 seconds\n",
      "[stacking patches] took 0.001595 seconds\n",
      "[converting to tensor] took 0.012057 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014060 seconds\n",
      "[converting PIL image to numpy] took 0.003614 seconds\n",
      "[stacking patches] took 0.001333 seconds\n",
      "[converting to tensor] took 0.013929 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015634 seconds\n",
      "[converting PIL image to numpy] took 0.003376 seconds\n",
      "[stacking patches] took 0.001111 seconds\n",
      "[converting to tensor] took 0.012854 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014267 seconds\n",
      "[converting PIL image to numpy] took 0.004218 seconds\n",
      "[stacking patches] took 0.001524 seconds\n",
      "[converting to tensor] took 0.012737 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014621 seconds\n",
      "[converting PIL image to numpy] took 0.004544 seconds\n",
      "[stacking patches] took 0.001366 seconds\n",
      "[converting to tensor] took 0.010645 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012334 seconds\n",
      "[converting PIL image to numpy] took 0.003512 seconds\n",
      "[stacking patches] took 0.001242 seconds\n",
      "[converting to tensor] took 0.011277 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013130 seconds\n",
      "[converting PIL image to numpy] took 0.004237 seconds\n",
      "[stacking patches] took 0.001363 seconds\n",
      "[converting to tensor] took 0.013461 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015167 seconds\n",
      "[converting PIL image to numpy] took 0.003362 seconds\n",
      "[stacking patches] took 0.001236 seconds\n",
      "[converting to tensor] took 0.013515 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.015190 seconds\n",
      "[converting PIL image to numpy] took 0.003345 seconds\n",
      "[stacking patches] took 0.001123 seconds\n",
      "[converting to tensor] took 0.013327 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.014818 seconds\n",
      "[converting PIL image to numpy] took 0.008764 seconds\n",
      "[stacking patches] took 0.001529 seconds\n",
      "[converting to tensor] took 0.011906 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014025 seconds\n",
      "[converting PIL image to numpy] took 0.003550 seconds\n",
      "[stacking patches] took 0.001137 seconds\n",
      "[converting to tensor] took 0.012813 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014292 seconds\n",
      "[converting PIL image to numpy] took 0.004477 seconds\n",
      "[stacking patches] took 0.001534 seconds\n",
      "[converting to tensor] took 0.013224 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015153 seconds\n",
      "[converting PIL image to numpy] took 0.003465 seconds\n",
      "[stacking patches] took 0.001159 seconds\n",
      "[converting to tensor] took 0.012785 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014275 seconds\n",
      "[converting PIL image to numpy] took 0.004241 seconds\n",
      "[stacking patches] took 0.001189 seconds\n",
      "[converting to tensor] took 0.012429 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013914 seconds\n",
      "[converting PIL image to numpy] took 0.003337 seconds\n",
      "[stacking patches] took 0.001280 seconds\n",
      "[converting to tensor] took 0.014273 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015853 seconds\n",
      "[converting PIL image to numpy] took 0.003304 seconds\n",
      "[stacking patches] took 0.001099 seconds\n",
      "[converting to tensor] took 0.012521 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.013908 seconds\n",
      "[converting PIL image to numpy] took 0.003360 seconds\n",
      "[stacking patches] took 0.001115 seconds\n",
      "[converting to tensor] took 0.013212 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014601 seconds\n",
      "[converting PIL image to numpy] took 0.003279 seconds\n",
      "[stacking patches] took 0.001168 seconds\n",
      "[converting to tensor] took 0.012538 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013986 seconds\n",
      "[converting PIL image to numpy] took 0.003362 seconds\n",
      "[stacking patches] took 0.001099 seconds\n",
      "[converting to tensor] took 0.010871 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012255 seconds\n",
      "[converting PIL image to numpy] took 0.003301 seconds\n",
      "[stacking patches] took 0.001259 seconds\n",
      "[converting to tensor] took 0.012944 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014493 seconds\n",
      "[converting PIL image to numpy] took 0.003445 seconds\n",
      "[stacking patches] took 0.001208 seconds\n",
      "[converting to tensor] took 0.011728 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013313 seconds\n",
      "[converting PIL image to numpy] took 0.004574 seconds\n",
      "[stacking patches] took 0.005905 seconds\n",
      "[converting to tensor] took 0.013727 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.019985 seconds\n",
      "[converting PIL image to numpy] took 0.003384 seconds\n",
      "[stacking patches] took 0.001217 seconds\n",
      "[converting to tensor] took 0.012408 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013967 seconds\n",
      "[converting PIL image to numpy] took 0.004917 seconds\n",
      "[stacking patches] took 0.001662 seconds\n",
      "[converting to tensor] took 0.014649 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.016653 seconds\n",
      "[converting PIL image to numpy] took 0.004338 seconds\n",
      "[stacking patches] took 0.001163 seconds\n",
      "[converting to tensor] took 0.010674 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.012221 seconds\n",
      "[converting PIL image to numpy] took 0.003293 seconds\n",
      "[stacking patches] took 0.001191 seconds\n",
      "[converting to tensor] took 0.011071 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.012562 seconds\n",
      "[converting PIL image to numpy] took 0.004414 seconds\n",
      "[stacking patches] took 0.001200 seconds\n",
      "[converting to tensor] took 0.011173 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012666 seconds\n",
      "[converting PIL image to numpy] took 0.004662 seconds\n",
      "[stacking patches] took 0.001084 seconds\n",
      "[converting to tensor] took 0.010936 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012444 seconds\n",
      "[converting PIL image to numpy] took 0.004878 seconds\n",
      "[stacking patches] took 0.001142 seconds\n",
      "[converting to tensor] took 0.010609 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012036 seconds\n",
      "[converting PIL image to numpy] took 0.004539 seconds\n",
      "[stacking patches] took 0.001070 seconds\n",
      "[converting to tensor] took 0.013107 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014453 seconds\n",
      "[converting PIL image to numpy] took 0.003284 seconds\n",
      "[stacking patches] took 0.001119 seconds\n",
      "[converting to tensor] took 0.012283 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013686 seconds\n",
      "[converting PIL image to numpy] took 0.004398 seconds\n",
      "[stacking patches] took 0.001107 seconds\n",
      "[converting to tensor] took 0.012920 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014314 seconds\n",
      "[converting PIL image to numpy] took 0.003952 seconds\n",
      "[stacking patches] took 0.001203 seconds\n",
      "[converting to tensor] took 0.012559 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014056 seconds\n",
      "[converting PIL image to numpy] took 0.003730 seconds\n",
      "[stacking patches] took 0.001160 seconds\n",
      "[converting to tensor] took 0.011986 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013445 seconds\n",
      "[converting PIL image to numpy] took 0.003280 seconds\n",
      "[stacking patches] took 0.001147 seconds\n",
      "[converting to tensor] took 0.012640 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014084 seconds\n",
      "[converting PIL image to numpy] took 0.011275 seconds\n",
      "[stacking patches] took 0.001101 seconds\n",
      "[converting to tensor] took 0.012011 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013425 seconds\n",
      "[converting PIL image to numpy] took 0.005338 seconds\n",
      "[stacking patches] took 0.001214 seconds\n",
      "[converting to tensor] took 0.014203 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015719 seconds\n",
      "[converting PIL image to numpy] took 0.011084 seconds\n",
      "[stacking patches] took 0.001138 seconds\n",
      "[converting to tensor] took 0.012686 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014120 seconds\n",
      "[converting PIL image to numpy] took 0.003317 seconds\n",
      "[stacking patches] took 0.001147 seconds\n",
      "[converting to tensor] took 0.012245 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013681 seconds\n",
      "[converting PIL image to numpy] took 0.003653 seconds\n",
      "[stacking patches] took 0.001091 seconds\n",
      "[converting to tensor] took 0.013255 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.014635 seconds\n",
      "[converting PIL image to numpy] took 0.004134 seconds\n",
      "[stacking patches] took 0.001209 seconds\n",
      "[converting to tensor] took 0.012497 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014005 seconds\n",
      "[converting PIL image to numpy] took 0.003201 seconds\n",
      "[stacking patches] took 0.001177 seconds\n",
      "[converting to tensor] took 0.010444 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.011904 seconds\n",
      "[converting PIL image to numpy] took 0.008740 seconds\n",
      "[stacking patches] took 0.001271 seconds\n",
      "[converting to tensor] took 0.011171 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012788 seconds\n",
      "[converting PIL image to numpy] took 0.004384 seconds\n",
      "[stacking patches] took 0.001256 seconds\n",
      "[converting to tensor] took 0.016311 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.017909 seconds\n",
      "[converting PIL image to numpy] took 0.011783 seconds\n",
      "[stacking patches] took 0.002025 seconds\n",
      "[converting to tensor] took 0.014563 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.017018 seconds\n",
      "[converting PIL image to numpy] took 0.005087 seconds\n",
      "[stacking patches] took 0.001164 seconds\n",
      "[converting to tensor] took 0.011877 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013369 seconds\n",
      "[converting PIL image to numpy] took 0.005214 seconds\n",
      "[stacking patches] took 0.001848 seconds\n",
      "[converting to tensor] took 0.012852 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015042 seconds\n",
      "[converting PIL image to numpy] took 0.003553 seconds\n",
      "[stacking patches] took 0.001270 seconds\n",
      "[converting to tensor] took 0.013297 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014923 seconds\n",
      "[converting PIL image to numpy] took 0.004966 seconds\n",
      "[stacking patches] took 0.001436 seconds\n",
      "[converting to tensor] took 0.013154 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014946 seconds\n",
      "[converting PIL image to numpy] took 0.003449 seconds\n",
      "[stacking patches] took 0.001135 seconds\n",
      "[converting to tensor] took 0.012624 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014099 seconds\n",
      "[converting PIL image to numpy] took 0.004725 seconds\n",
      "[stacking patches] took 0.001682 seconds\n",
      "[converting to tensor] took 0.013210 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015289 seconds\n",
      "[converting PIL image to numpy] took 0.003753 seconds\n",
      "[stacking patches] took 0.001789 seconds\n",
      "[converting to tensor] took 0.012730 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014832 seconds\n",
      "[converting PIL image to numpy] took 0.011084 seconds\n",
      "[stacking patches] took 0.001200 seconds\n",
      "[converting to tensor] took 0.016286 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.017843 seconds\n",
      "[converting PIL image to numpy] took 0.006413 seconds\n",
      "[stacking patches] took 0.001609 seconds\n",
      "[converting to tensor] took 0.011741 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013722 seconds\n",
      "[converting PIL image to numpy] took 0.011316 seconds\n",
      "[stacking patches] took 0.001139 seconds\n",
      "[converting to tensor] took 0.010665 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.012142 seconds\n",
      "[converting PIL image to numpy] took 0.004308 seconds\n",
      "[stacking patches] took 0.001445 seconds\n",
      "[converting to tensor] took 0.013501 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015292 seconds\n",
      "[converting PIL image to numpy] took 0.004200 seconds\n",
      "[stacking patches] took 0.001165 seconds\n",
      "[converting to tensor] took 0.012883 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014456 seconds\n",
      "[converting PIL image to numpy] took 0.004142 seconds\n",
      "[stacking patches] took 0.001146 seconds\n",
      "[converting to tensor] took 0.010594 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012042 seconds\n",
      "[converting PIL image to numpy] took 0.004111 seconds\n",
      "[stacking patches] took 0.001337 seconds\n",
      "[converting to tensor] took 0.011781 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.013527 seconds\n",
      "[converting PIL image to numpy] took 0.003522 seconds\n",
      "[stacking patches] took 0.001118 seconds\n",
      "[converting to tensor] took 0.010593 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.012046 seconds\n",
      "[converting PIL image to numpy] took 0.003677 seconds\n",
      "[stacking patches] took 0.001297 seconds\n",
      "[converting to tensor] took 0.012207 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013961 seconds\n",
      "[converting PIL image to numpy] took 0.004300 seconds\n",
      "[stacking patches] took 0.001341 seconds\n",
      "[converting to tensor] took 0.012813 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014518 seconds\n",
      "[converting PIL image to numpy] took 0.003937 seconds\n",
      "[stacking patches] took 0.001140 seconds\n",
      "[converting to tensor] took 0.013782 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015308 seconds\n",
      "[converting PIL image to numpy] took 0.003688 seconds\n",
      "[stacking patches] took 0.001472 seconds\n",
      "[converting to tensor] took 0.012463 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.014236 seconds\n",
      "[converting PIL image to numpy] took 0.003440 seconds\n",
      "[stacking patches] took 0.001171 seconds\n",
      "[converting to tensor] took 0.010584 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012047 seconds\n",
      "[converting PIL image to numpy] took 0.003333 seconds\n",
      "[stacking patches] took 0.001253 seconds\n",
      "[converting to tensor] took 0.013026 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014578 seconds\n",
      "[converting PIL image to numpy] took 0.003751 seconds\n",
      "[stacking patches] took 0.001118 seconds\n",
      "[converting to tensor] took 0.013897 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015301 seconds\n",
      "[converting PIL image to numpy] took 0.003331 seconds\n",
      "[stacking patches] took 0.001155 seconds\n",
      "[converting to tensor] took 0.011627 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013059 seconds\n",
      "[converting PIL image to numpy] took 0.003270 seconds\n",
      "[stacking patches] took 0.001175 seconds\n",
      "[converting to tensor] took 0.010024 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.011491 seconds\n",
      "[converting PIL image to numpy] took 0.003298 seconds\n",
      "[stacking patches] took 0.001045 seconds\n",
      "[converting to tensor] took 0.011667 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012997 seconds\n",
      "[converting PIL image to numpy] took 0.003785 seconds\n",
      "[stacking patches] took 0.001478 seconds\n",
      "[converting to tensor] took 0.013284 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015070 seconds\n",
      "[converting PIL image to numpy] took 0.003430 seconds\n",
      "[stacking patches] took 0.001140 seconds\n",
      "[converting to tensor] took 0.013922 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.015349 seconds\n",
      "[converting PIL image to numpy] took 0.003791 seconds\n",
      "[stacking patches] took 0.001090 seconds\n",
      "[converting to tensor] took 0.010307 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.011688 seconds\n",
      "[converting PIL image to numpy] took 0.003427 seconds\n",
      "[stacking patches] took 0.001148 seconds\n",
      "[converting to tensor] took 0.011544 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012986 seconds\n",
      "[converting PIL image to numpy] took 0.003689 seconds\n",
      "[stacking patches] took 0.001076 seconds\n",
      "[converting to tensor] took 0.011839 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013196 seconds\n",
      "[converting PIL image to numpy] took 0.003397 seconds\n",
      "[stacking patches] took 0.001161 seconds\n",
      "[converting to tensor] took 0.013253 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.014743 seconds\n",
      "[converting PIL image to numpy] took 0.004487 seconds\n",
      "[stacking patches] took 0.001297 seconds\n",
      "[converting to tensor] took 0.012362 seconds\n",
      "[applying vision transform] took 0.000009 seconds\n",
      "[getting latest clip] took 0.014039 seconds\n",
      "[converting PIL image to numpy] took 0.004297 seconds\n",
      "[stacking patches] took 0.001190 seconds\n",
      "[converting to tensor] took 0.011630 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.013145 seconds\n",
      "[converting PIL image to numpy] took 0.003813 seconds\n",
      "[stacking patches] took 0.001138 seconds\n",
      "[converting to tensor] took 0.010343 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.011848 seconds\n",
      "[converting PIL image to numpy] took 0.009255 seconds\n",
      "[stacking patches] took 0.001275 seconds\n",
      "[converting to tensor] took 0.010329 seconds\n",
      "[applying vision transform] took 0.000001 seconds\n",
      "[getting latest clip] took 0.012112 seconds\n",
      "[converting PIL image to numpy] took 0.003803 seconds\n",
      "[stacking patches] took 0.001103 seconds\n",
      "[converting to tensor] took 0.013260 seconds\n",
      "[applying vision transform] took 0.000002 seconds\n",
      "[getting latest clip] took 0.014733 seconds\n"
     ]
    }
   ],
   "source": [
    "clip, label = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 760, 1352])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_example = torch.rand(4, 3, 760, 1352)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import torch\n",
    "from fish_benchmark.debug import step_timer\n",
    "\n",
    "class TorchVisionPreprocessor:\n",
    "    def __init__(self, crop_size=(224, 224), resize_shortest=256,\n",
    "                 mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),\n",
    "                 interpolation=InterpolationMode.BICUBIC):\n",
    "\n",
    "        self.resize = v2.Resize(resize_shortest, interpolation=interpolation, antialias=False)\n",
    "        self.crop = v2.CenterCrop(crop_size)\n",
    "        self.mean = torch.tensor(mean).view(3, 1, 1)\n",
    "        self.std = torch.tensor(std).view(3, 1, 1)\n",
    "\n",
    "    def __call__(self, image_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        with step_timer(\"resize\"):\n",
    "            image_tensor = self.resize(image_tensor)\n",
    "        with step_timer(\"crop\"):\n",
    "            image_tensor = self.crop(image_tensor)\n",
    "\n",
    "        with step_timer(\"normalize\"):\n",
    "            image_tensor = (image_tensor - self.mean) / self.std\n",
    "\n",
    "        return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[resize] took 0.008087 seconds\n",
      "[crop] took 0.000083 seconds\n",
      "[normalize] took 0.000823 seconds\n",
      "[Preprocess] took 0.009111 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preprocessor = TorchVisionPreprocessor()\n",
    "with step_timer(\"Preprocess\"):\n",
    "    preprocessor(clip).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
