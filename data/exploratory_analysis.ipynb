{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "config = yaml.safe_load(open(\"../config/datasets.yml\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/j_sun/jth264/abby\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"AbbyFrames\"\n",
    "DATASET_DIR = config[DATASET][\"path\"]\n",
    "print(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13559, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fish_benchmark.utils import get_files_of_type\n",
    "import numpy as np\n",
    "annotation_files = get_files_of_type(DATASET_DIR, \".txt\")\n",
    "\n",
    "annotations = []\n",
    "for file in annotation_files:\n",
    "    annotations.append(np.loadtxt(file, delimiter=\"\\t\"))\n",
    "\n",
    "annotations = np.concatenate(annotations, axis=0)\n",
    "annotations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1307.,  135.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.data.dataset import AbbyDataset\n",
    "dataset = AbbyDataset(\n",
    "        DATASET_DIR, \n",
    "        train=True, \n",
    "        transform=None, \n",
    "        label_type='onehot', \n",
    "        window_size=32, \n",
    "        tolerance_region = 15,\n",
    "        samples_per_window = 1,\n",
    "        step_size=1, \n",
    "        is_image_dataset=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame, label = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([220, 220, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12539it [00:06, 1946.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1696, 0.0757])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "labels = []\n",
    "for frame, label in tqdm(dataset):\n",
    "    labels.append(label)\n",
    "\n",
    "labels = torch.stack(labels)\n",
    "print(labels.sum(axis=0)/labels.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
