{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import webdataset as wds\n",
    "path = \"/share/j_sun/jth264/bites_frame_annotation\" \n",
    "# dataset = \"SR_070723_GH030275-000000..000099.tar\"\n",
    "# url = os.path.join(path, dataset)\n",
    "tar_files = [os.path.join(path, tarfile) for tarfile in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.data.dataset import HeinFishBehavior\n",
    "dataset = HeinFishBehavior(tar_files=tar_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataset))\n",
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "processed_image = processor(sample[0], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image.pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_image\n",
    "from torchvision.transforms import ToPILImage\n",
    "to_pil = ToPILImage()\n",
    "img_pil = to_pil(processed_image['pixel_values'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[1]\n",
    "categories = dataset.categories\n",
    "for label in sample[1]:\n",
    "    print(categories[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, sample in enumerate(dataset):\n",
    "    if id % 100 == 0:\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = wds.DataPipeline(\n",
    "        wds.SimpleShardList(tar_files),\n",
    "        wds.decode(\"pil\"),\n",
    "        wds.to_tuple(\"png\", \"json\")\n",
    "    )\n",
    "dataset = wds.WebDataset(tar_files).decode(\"pil\").to_tuple(\"png\", \"json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = sample[1]\n",
    "\n",
    "for event in annotation['events']:\n",
    "    print(event['behavior']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what is inside the tar file\n",
    "import tarfile\n",
    "with tarfile.open(url, 'r') as tar:\n",
    "    tar.extractall(path=path)\n",
    "    print(tar.getnames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"SR_070723_GH030275_000033.png\"\n",
    "from PIL import Image\n",
    "image = Image.open(os.path.join(path, image_path))\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = [i for i in range (10)]\n",
    "with open(\"data.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=1)\n",
    "\n",
    "with open(\"data.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import Caltech101\n",
    "\n",
    "dataset = Caltech101(root=\".\", target_type = \"category\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(1, 'tensor.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(torch.load('tensor.pt')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.models import get_input_transform\n",
    "\n",
    "transform = get_input_transform(\"dino\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = torch.rand(16, 3, 1500, 1500)\n",
    "transform(video).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.data.dataset import HeinFishBehaviorSlidingWindow\n",
    "import yaml\n",
    "config = yaml.safe_load(open(\"../config/datasets.yml\")) \n",
    "DATASET = \"HeinFishBehaviorSlidingWindow\"\n",
    "dataset = HeinFishBehaviorSlidingWindow(\n",
    "    path = config[DATASET]['path']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video, annotation = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.models import get_input_transform\n",
    "transform = get_input_transform(\"videomae\")\n",
    "transform(video).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.data.dataset import HeinFishBehavior\n",
    "import yaml\n",
    "from fish_benchmark.models import get_input_transform\n",
    "transform = get_input_transform(\"swinv2\", do_resize=False)\n",
    "config = yaml.safe_load(open(\"../config/datasets.yml\")) \n",
    "DATASET = \"HeinFishBehavior\"\n",
    "dataset = HeinFishBehavior(\n",
    "    path = config[DATASET]['path'], \n",
    "    transform = transform \n",
    ")\n",
    "image, annotation = next(iter(dataset))\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for id, (image, annotation) in tqdm(enumerate(dataset)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fish_benchmark.data.dataset import AbbyDataset\n",
    "import yaml\n",
    "config = yaml.safe_load(open(\"../config/datasets.yml\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"Abby\"\n",
    "dataset = AbbyDataset(\n",
    "    path = config[DATASET]['path'], \n",
    "    transform = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame, label = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for id, (frame, label) in tqdm(enumerate(dataset)):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jth264/.conda/envs/benchmark/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from fish_benchmark.data.dataset import get_dataset\n",
    "from fish_benchmark.models import get_input_transform\n",
    "import yaml\n",
    "PATH = \"/share/j_sun/jth264/bites_frame_annotation_splitted\"\n",
    "dataset = get_dataset(\"HeinFishBehaviorSlidingWindow\", path = PATH, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jth264/.conda/envs/benchmark/lib/python3.12/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1520, 2704, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame, label = next(iter(dataset))\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_dataset() got an unexpected keyword argument 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m input_transform = get_input_transform(\u001b[33m\"\u001b[39m\u001b[33mdino\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m dataset = \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHeinFishBehavior\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_transform\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: get_dataset() got an unexpected keyword argument 'transform'"
     ]
    }
   ],
   "source": [
    "input_transform = get_input_transform(\"dino\")\n",
    "dataset = get_dataset(\"HeinFishBehavior\", path = PATH, train=True, transform=input_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jth264/.conda/envs/benchmark/lib/python3.12/site-packages/webdataset/compat.py:389: UserWarning: WebDataset(shardshuffle=...) is None; set explicitly to False or a number\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1520, 2704, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame, label = next(iter(dataset))\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
