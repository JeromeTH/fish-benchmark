{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/drive/folders/12dPNkATHe4xJP0DOFvI6ke6LoNT9KhIR\"\n",
    "data_path = \"/share/j_sun/jth264/sample_fish_data\"\n",
    "import av\n",
    "import os\n",
    "video_path = os.path.join(data_path, \"GH030275_stab.MP4\")\n",
    "container = av.open(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container.streams.video[0].frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "import pandas as pd\n",
    "from fish_benchmark.utils import PriorityQueue\n",
    "\n",
    "class Behavior(BaseModel):\n",
    "    '''\n",
    "    A behavior in the BORIS annotation format.\n",
    "    '''\n",
    "    name: str\n",
    "    category: str\n",
    "    type: str\n",
    "    \n",
    "class Event(BaseModel):\n",
    "    start_time: float\n",
    "    end_time: float\n",
    "    start_frame: int\n",
    "    end_frame: int\n",
    "    behavior: Behavior\n",
    "    subject: str\n",
    "\n",
    "class Metadata(BaseModel):\n",
    "    '''\n",
    "    Metadata for a BORIS annotated video.\n",
    "    '''\n",
    "    observation_id: str\n",
    "    observation_date: str\n",
    "    observation_type: str\n",
    "    source: str\n",
    "    fps: float\n",
    "    media_duration: float\n",
    "    time_offset: float \n",
    "\n",
    "class MediaAnnotation:\n",
    "    '''\n",
    "    A BORIS annotated video and related conversion methods.\n",
    "    '''\n",
    "    def __init__(self, annotation_path):\n",
    "        self.df = self.read_df(annotation_path)\n",
    "        self.metadata: Metadata = self.load_metadata()\n",
    "        self.behaviors: List[Behavior] = self.load_behaviors()\n",
    "        self.events: List[Event] = self.load_events()\n",
    "\n",
    "    def read_df(self, annotation_path):\n",
    "        df = pd.read_csv(annotation_path)\n",
    "        df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "        return df\n",
    "\n",
    "    def load_metadata(self):\n",
    "        '''\n",
    "        Load metadata from a BORIS file.\n",
    "        '''\n",
    "        df = self.df\n",
    "        metadata = Metadata(\n",
    "            observation_id=df['observation_id'][0],\n",
    "            observation_date=df['observation_date'][0],\n",
    "            observation_type=df['observation_type'][0],\n",
    "            source=df['source'][0],\n",
    "            fps=df['fps_(frame/s)'][0],\n",
    "            media_duration=df['media_duration_(s)'][0],\n",
    "            time_offset=df['time_offset_(s)'][0]\n",
    "        )\n",
    "        return metadata\n",
    "\n",
    "    def load_behaviors(self):\n",
    "        '''\n",
    "        Load behaviors from a BORIS file.\n",
    "        '''\n",
    "        df = self.df\n",
    "        behaviors = df.groupby(['behavior', 'behavioral_category', 'behavior_type']).size().reset_index(name='count')\n",
    "        behavior_list = []\n",
    "        for _, row in behaviors.iterrows():\n",
    "            behavior=Behavior(\n",
    "                    name=row['behavior'],\n",
    "                    category=row['behavioral_category'],\n",
    "                    type=row['behavior_type']\n",
    "                )\n",
    "            behavior_list.append(behavior)\n",
    "        self.behaviors = behavior_list\n",
    "\n",
    "    def load_events(self):\n",
    "        '''\n",
    "        Load events from a BORIS file.\n",
    "        '''\n",
    "        df = self.df\n",
    "        events = []\n",
    "        for _, row in df.iterrows():\n",
    "            event = Event(\n",
    "                start_time=row['start_(s)'],\n",
    "                end_time=row['stop_(s)'],\n",
    "                start_frame=self.to_frame(row['start_(s)']),\n",
    "                end_frame=self.to_frame(row['stop_(s)']),\n",
    "                behavior=Behavior(\n",
    "                    name=row['behavior'],\n",
    "                    category=row['behavioral_category'],\n",
    "                    type=row['behavior_type']\n",
    "                ),\n",
    "                subject=row['subject']\n",
    "            )\n",
    "            events.append(event)\n",
    "        return events\n",
    "\n",
    "    def load_video(self, video_path):\n",
    "        '''\n",
    "        Load a video from a path.\n",
    "        '''\n",
    "        self.container = av.open(video_path)\n",
    "        self.frame_count = self.container.streams.video[0].frames\n",
    "        self.check_fps_match()\n",
    "\n",
    "    def check_fps_match(self):\n",
    "        annotated_frame_count = int(self.metadata.media_duration * self.metadata.fps)\n",
    "        #1 frame error margin\n",
    "        if abs(annotated_frame_count - self.frame_count) > 1:\n",
    "            raise ValueError(f\"frames mismatch: expected {annotated_frame_count} but got {self.frame_count}\")\n",
    "    \n",
    "    def to_frame(self, timestamp):\n",
    "        '''\n",
    "        Convert a timestamp to a frame number.\n",
    "        '''\n",
    "        return int((timestamp - self.metadata.time_offset)* self.metadata.fps)\n",
    "    \n",
    "    def to_timestamp(self, frame):\n",
    "        '''\n",
    "        Convert a frame number to a timestamp.\n",
    "        '''\n",
    "        return frame / self.metadata.fps + self.metadata.time_offset\n",
    "    \n",
    "    def stream_frame_annotations(self):\n",
    "        '''\n",
    "        Stream the video frames and their annotations.\n",
    "        Algorithm: \n",
    "        Sort the events by start time\n",
    "        maintain the set of active events with a priority queue, priority determined by the end time of each event\n",
    "        For each frame in the video:\n",
    "            Check if the next closest event should start.\n",
    "            If so, add it to the active events\n",
    "            Annotate the frame with the active events\n",
    "            check if the top most event should end\n",
    "            If so, remove it from the active events\n",
    "        \n",
    "        Yields a tuple a training example compatible with the webdataset format. \n",
    "        e.g.\n",
    "            <video_name>_<frame_id>.json #the annotation and metadata\n",
    "            <video_name>_<frame_id>.png #the video frame\n",
    "        '''\n",
    "        #put events in a priority queue\n",
    "        event_queue = PriorityQueue()\n",
    "        for id, event in enumerate(self.events):\n",
    "            event_queue.push((event.start_frame,id, event))\n",
    "        # Initialize the priority queue\n",
    "        active_events = PriorityQueue()\n",
    "        for frame_id, frame in enumerate(self.container.decode(video=0)):\n",
    "            # Check if any events should start\n",
    "            while event_queue and event_queue.peek()[0] <= frame_id:\n",
    "                _, id, event = event_queue.pop()\n",
    "                active_events.push((event.end_frame, id, event))\n",
    "            # Annotate the frame with the active events\n",
    "            annotations = {'events': [], \n",
    "                            'metadata': self.metadata.model_dump(),\n",
    "                            'video_name': os.path.basename(video_path),\n",
    "                            'frame_id': frame_id}\n",
    "            # annotations should be a list of dictionaries which would later be converted to json\n",
    "            # in the webdataset format\n",
    "            for _, _, event in active_events.to_list():\n",
    "                annotations['events'].append(event.model_dump())\n",
    "\n",
    "            yield frame.to_ndarray(format=\"rgb24\"), annotations\n",
    "            # Check if any events should end\n",
    "            while not active_events.is_empty() and active_events.peek()[0] <= frame_id:\n",
    "                active_events.pop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "annotation_path  = os.path.join(data_path, \"JGL_DaaiBoui_SR_070723_GH030275.csv\")\n",
    "df = pd.read_csv(annotation_path)\n",
    "df.head()\n",
    "#rename all columns to snake_case\n",
    "df.columns = df.columns.str.replace(' ', '_').str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = MediaAnnotation(annotation_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation.load_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame, label = next(annotation.stream_frame_annotations())\n",
    "print(frame.shape)\n",
    "print(label['metadata'])\n",
    "print(label['video_name'])\n",
    "print(label['frame_id'])\n",
    "for event in label['events']:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first annotation\n",
    "#see how fast the stream is calculate fps \n",
    "for id, _ in enumerate(annotation.stream_frame_annotations()):\n",
    "    if(id % 100 == 0):\n",
    "        print(id)\n",
    "#check the fps\n",
    "import time\n",
    "prev = time.time()\n",
    "for id, _ in enumerate(annotation.stream_frame_annotations()):\n",
    "    if(id % 100 == 0):\n",
    "        now = time.time()\n",
    "        print(id)\n",
    "        print(f\"fps: {100/(now - prev)}\")\n",
    "        prev = now\n",
    "\n",
    "#annotating ~35 fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event1 = Event(\n",
    "    start_time=0,\n",
    "    end_time=1,\n",
    "    start_frame=0,\n",
    "    end_frame=1,\n",
    "    behavior=Behavior(\n",
    "        name=\"swim\",\n",
    "        category=\"movement\",\n",
    "        type=\"active\"\n",
    "    ),\n",
    "    subject=\"fish1\"\n",
    ")\n",
    "event2 = Event(\n",
    "    start_time=1,\n",
    "    end_time=2,\n",
    "    start_frame=1,\n",
    "    end_frame=2,\n",
    "    behavior=Behavior(\n",
    "        name=\"swim\",\n",
    "        category=\"movement\",\n",
    "        type=\"active\"\n",
    "    ),\n",
    "    subject=\"fish1\"\n",
    ")\n",
    "pq = PriorityQueue()\n",
    "\n",
    "pq.push((event1.start_frame, event1))\n",
    "pq.push((event2.start_frame, event2))\n",
    "\n",
    "pq.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CUB_EMBED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
