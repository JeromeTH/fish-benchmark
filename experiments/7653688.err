wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: mmw243 (fish-benchmark) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in ./logs/wandb/run-20250420_231922-auh3ox1e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-durian-21
wandb: ⭐️ View project at https://wandb.ai/fish-benchmark/AbbyFrames_training
wandb: 🚀 View run at https://wandb.ai/fish-benchmark/AbbyFrames_training/runs/auh3ox1e
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
/home/mmw243/.conda/envs/clean/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.
You are using a CUDA device ('NVIDIA RTX 6000 Ada Generation') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/mmw243/.conda/envs/clean/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type            | Params | Mode 
--------------------------------------------------
0 | model | MediaClassifier | 87.0 M | train
--------------------------------------------------
394 K     Trainable params
86.6 M    Non-trainable params
87.0 M    Total params
347.901   Total estimated model params size (MB)
5         Modules in train mode
224       Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
/home/mmw243/.conda/envs/clean/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:384: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['train_loss', 'train_recall', 'train_precision', 'train_f1', 'train_acc', 'train_class_0_pos_count', 'train_class_1_pos_count', 'train_class_0_pos_pred_count', 'train_class_1_pos_pred_count', 'train_class_0_accuracy', 'train_class_1_accuracy', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?
`Trainer.fit` stopped: `max_epochs=1` reached.
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                        epoch ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                    train_acc ▇██▃▃█▇███▇▅█▆█████▃███▆████▆██▇▆▆▆███▁▆
wandb:       train_class_0_accuracy █▆▆█▄▇▇▇▅███▃▃▃▆▆▆█▄██▂▆▆▆█▇▇▆▇▅▆▃█▅▇▇▁▅
wandb:      train_class_0_pos_count █▁▂▂▇▁▂▆▁▁▁▁▁▁▁▁▁▁▅▁▂▃▂▁▂▁▁▁▁▃▂▁▅▄▁▁▁▁▅▁
wandb: train_class_0_pos_pred_count ▇▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▂▁▁▁▁▁▁▁▁▁▁▂▃▁▁▂▁▁▁▁
wandb:       train_class_1_accuracy █████████████████████▁▇██████████▅▅▅████
wandb:      train_class_1_pos_count ▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁▂▁▁█▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂
wandb: train_class_1_pos_pred_count ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:                     train_f1 ▃▁▁▂▂▂▅▅▄▄▄▄▄▄▅▅▆▆▄▄▃▄▂▅▅██▇█▅▇▃▆██▅▅▅▅▅
wandb:                   train_loss ▁▁▁▁▃▃▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁█▄▂▁▁▂▁▂▁▂▂▂▁▃▁▁▁▁
wandb:              train_precision ███▁██████▄▄▄█▄▄████▇▇▇▇▇██▃███▇██▄▄▃▃▃▆
wandb:                 train_recall ██▂▂▁▁▂▂▄▄█▅▅▅▂█▂▂▇█▄▃████▅█▂▅▄▄▇█▇▇▇▇█▃
wandb:          trainer/global_step ▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇█
wandb: 
wandb: Run summary:
wandb:                        epoch 0
wandb:                    train_acc 0.92188
wandb:       train_class_0_accuracy 0.84375
wandb:      train_class_0_pos_count 18
wandb: train_class_0_pos_pred_count 23
wandb:       train_class_1_accuracy 0.96875
wandb:      train_class_1_pos_count 0
wandb: train_class_1_pos_pred_count 0
wandb:                     train_f1 0.87805
wandb:                   train_loss 0.12766
wandb:              train_precision 0.78261
wandb:                 train_recall 1
wandb:          trainer/global_step 2959
wandb: 
wandb: 🚀 View run expert-durian-21 at: https://wandb.ai/fish-benchmark/AbbyFrames_training/runs/auh3ox1e
wandb: ⭐️ View project at: https://wandb.ai/fish-benchmark/AbbyFrames_training
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./logs/wandb/run-20250420_231922-auh3ox1e/logs
